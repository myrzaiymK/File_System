import os
import pickle5 as pickle
# from path import file_s_place, directory
import hashlib
# from create import create_hash
import sys
# from config import fiel_test
# # print(hashlib.algorithms_guaranteed)
#
# # _, command, *args = sys.argv
# a = 'dfghjkl'
# for i in os.listdir(directory):
#     hash1 = create_hash(i)
#
# h = hashlib.md5(file_s_place.encode('utf-8'))
# a = h.hexdigest()
#
# count = 0
# l = []
# while count < 100:
#     file = str(count) + '.txt'
#     size = 0
#     dict_f = {
#         'name': file,
#         'bytes': size,
#         'hash': hash1,
#     }
#     count += 1
#     l.append(dict_f)
# # print(l)

# with open('file_s_place', 'rb') as f:
#     # file_size = os.stat(file_s_place).st_size
#     ac = pickle.load(f)
#     print(ac)



# def create_db(file, file_size):
#     list_d = []
#     a_list = []
#     dict_f = {
#         'name': file,
#         'bytes': file_size,
#         # 'hash': file_hash,
#     }
#     list_d.append(dict_f)
#     f = open(file_s_place, 'rb')
#     list_d = list(pickle.load(f))
#     list_d.append(dict_f)
#     pickle.dump(list_d, open(file_s_place, 'wb'))
#     print(list_d)

# with open(file_s_place, 'wb') as f


 # with open(path, 'r') as f:
 #        hashes = f.read().split('\n')[:-1]  # start stop step slice


# with open(fiel_test, 'rb') as f:
#     a = f.read()
#     print(a)


# path_2 = os.getcwd() + '/names_example.data'
